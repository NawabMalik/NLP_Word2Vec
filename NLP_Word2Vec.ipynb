{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"Probably the most effective way to achieve paragraph unity is to express the central idea of the paragraph in a \n",
    "topic sentence. Topic sentences are similar to mini thesis statements. Like a thesis statement, a topic sentence has a specific\n",
    "main point. Whereas the thesis is the main point of the essay, the topic sentence is the main point of the paragraph. Like the \n",
    "thesis statement, a topic sentence has a unifying function. But a thesis statement or topic sentence alone doesn’t guarantee \n",
    "unity. An essay is unified if all the paragraphs relate to the thesis, whereas a paragraph is unified if all the sentences \n",
    "relate to the topic sentence. Note: Not all paragraphs need topic sentences. In particular, opening and closing paragraphs, \n",
    "which serve different functions from body paragraphs, generally don’t have topic sentences.\n",
    "In academic writing, the topic sentence nearly always works best at the beginning of a paragraph so that the reader knows what \n",
    "to expect:\n",
    "The embrace of Twitter by politicians and journalists has been one of its most notable features in recent years: for both groups\n",
    "the use of Twitter is becoming close to a requirement. —Paul Bernal, “A Defence of Responsible Tweeting”\n",
    "This topic sentence forecasts the central idea or main point of the paragraph: “politicians” and “journalists” rely on Twitter.\n",
    "The rest of the paragraph will focus on these two Twitter-user groups, thereby fulfilling the promise made by the topic sentence.\n",
    "By avoiding irrelevant information that does not relate to the topic sentence, you can compose a unified paragraph.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably the most effective way to achieve paragraph unity is to express the central idea of the paragraph in a  topic sentence  topic sentences are similar to mini thesis statements  like a thesis statement  a topic sentence has a specific main point  whereas the thesis is the main point of the essay  the topic sentence is the main point of the paragraph  like the  thesis statement  a topic sentence has a unifying function  but a thesis statement or topic sentence alone doesn t guarantee  unity  an essay is unified if all the paragraphs relate to the thesis  whereas a paragraph is unified if all the sentences  relate to the topic sentence  note  not all paragraphs need topic sentences  in particular  opening and closing paragraphs   which serve different functions from body paragraphs  generally don t have topic sentences  in academic writing  the topic sentence nearly always works best at the beginning of a paragraph so that the reader knows what  to expect  the embrace of twitter by politicians and journalists has been one of its most notable features in recent years  for both groups the use of twitter is becoming close to a requirement   paul bernal   a defence of responsible tweeting  this topic sentence forecasts the central idea or main point of the paragraph   politicians  and  journalists  rely on twitter  the rest of the paragraph will focus on these two twitter user groups  thereby fulfilling the promise made by the topic sentence  by avoiding irrelevant information that does not relate to the topic sentence  you can compose a unified paragraph '"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=re.sub('[^a-zA-Z]', ' ', paragraph)\n",
    "text=text.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['probably',\n",
       "  'the',\n",
       "  'most',\n",
       "  'effective',\n",
       "  'way',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  'paragraph',\n",
       "  'unity',\n",
       "  'is',\n",
       "  'to',\n",
       "  'express',\n",
       "  'the',\n",
       "  'central',\n",
       "  'idea',\n",
       "  'of',\n",
       "  'the',\n",
       "  'paragraph',\n",
       "  'in',\n",
       "  'a',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'topic',\n",
       "  'sentences',\n",
       "  'are',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'mini',\n",
       "  'thesis',\n",
       "  'statements',\n",
       "  'like',\n",
       "  'a',\n",
       "  'thesis',\n",
       "  'statement',\n",
       "  'a',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'has',\n",
       "  'a',\n",
       "  'specific',\n",
       "  'main',\n",
       "  'point',\n",
       "  'whereas',\n",
       "  'the',\n",
       "  'thesis',\n",
       "  'is',\n",
       "  'the',\n",
       "  'main',\n",
       "  'point',\n",
       "  'of',\n",
       "  'the',\n",
       "  'essay',\n",
       "  'the',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'is',\n",
       "  'the',\n",
       "  'main',\n",
       "  'point',\n",
       "  'of',\n",
       "  'the',\n",
       "  'paragraph',\n",
       "  'like',\n",
       "  'the',\n",
       "  'thesis',\n",
       "  'statement',\n",
       "  'a',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'has',\n",
       "  'a',\n",
       "  'unifying',\n",
       "  'function',\n",
       "  'but',\n",
       "  'a',\n",
       "  'thesis',\n",
       "  'statement',\n",
       "  'or',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'alone',\n",
       "  'doesn',\n",
       "  't',\n",
       "  'guarantee',\n",
       "  'unity',\n",
       "  'an',\n",
       "  'essay',\n",
       "  'is',\n",
       "  'unified',\n",
       "  'if',\n",
       "  'all',\n",
       "  'the',\n",
       "  'paragraphs',\n",
       "  'relate',\n",
       "  'to',\n",
       "  'the',\n",
       "  'thesis',\n",
       "  'whereas',\n",
       "  'a',\n",
       "  'paragraph',\n",
       "  'is',\n",
       "  'unified',\n",
       "  'if',\n",
       "  'all',\n",
       "  'the',\n",
       "  'sentences',\n",
       "  'relate',\n",
       "  'to',\n",
       "  'the',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'note',\n",
       "  'not',\n",
       "  'all',\n",
       "  'paragraphs',\n",
       "  'need',\n",
       "  'topic',\n",
       "  'sentences',\n",
       "  'in',\n",
       "  'particular',\n",
       "  'opening',\n",
       "  'and',\n",
       "  'closing',\n",
       "  'paragraphs',\n",
       "  'which',\n",
       "  'serve',\n",
       "  'different',\n",
       "  'functions',\n",
       "  'from',\n",
       "  'body',\n",
       "  'paragraphs',\n",
       "  'generally',\n",
       "  'don',\n",
       "  't',\n",
       "  'have',\n",
       "  'topic',\n",
       "  'sentences',\n",
       "  'in',\n",
       "  'academic',\n",
       "  'writing',\n",
       "  'the',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'nearly',\n",
       "  'always',\n",
       "  'works',\n",
       "  'best',\n",
       "  'at',\n",
       "  'the',\n",
       "  'beginning',\n",
       "  'of',\n",
       "  'a',\n",
       "  'paragraph',\n",
       "  'so',\n",
       "  'that',\n",
       "  'the',\n",
       "  'reader',\n",
       "  'knows',\n",
       "  'what',\n",
       "  'to',\n",
       "  'expect',\n",
       "  'the',\n",
       "  'embrace',\n",
       "  'of',\n",
       "  'twitter',\n",
       "  'by',\n",
       "  'politicians',\n",
       "  'and',\n",
       "  'journalists',\n",
       "  'has',\n",
       "  'been',\n",
       "  'one',\n",
       "  'of',\n",
       "  'its',\n",
       "  'most',\n",
       "  'notable',\n",
       "  'features',\n",
       "  'in',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'for',\n",
       "  'both',\n",
       "  'groups',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'twitter',\n",
       "  'is',\n",
       "  'becoming',\n",
       "  'close',\n",
       "  'to',\n",
       "  'a',\n",
       "  'requirement',\n",
       "  'paul',\n",
       "  'bernal',\n",
       "  'a',\n",
       "  'defence',\n",
       "  'of',\n",
       "  'responsible',\n",
       "  'tweeting',\n",
       "  'this',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'forecasts',\n",
       "  'the',\n",
       "  'central',\n",
       "  'idea',\n",
       "  'or',\n",
       "  'main',\n",
       "  'point',\n",
       "  'of',\n",
       "  'the',\n",
       "  'paragraph',\n",
       "  'politicians',\n",
       "  'and',\n",
       "  'journalists',\n",
       "  'rely',\n",
       "  'on',\n",
       "  'twitter',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'the',\n",
       "  'paragraph',\n",
       "  'will',\n",
       "  'focus',\n",
       "  'on',\n",
       "  'these',\n",
       "  'two',\n",
       "  'twitter',\n",
       "  'user',\n",
       "  'groups',\n",
       "  'thereby',\n",
       "  'fulfilling',\n",
       "  'the',\n",
       "  'promise',\n",
       "  'made',\n",
       "  'by',\n",
       "  'the',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'by',\n",
       "  'avoiding',\n",
       "  'irrelevant',\n",
       "  'information',\n",
       "  'that',\n",
       "  'does',\n",
       "  'not',\n",
       "  'relate',\n",
       "  'to',\n",
       "  'the',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'you',\n",
       "  'can',\n",
       "  'compose',\n",
       "  'a',\n",
       "  'unified',\n",
       "  'paragraph']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets convert the paragraph into sentences and sentences into words:\n",
    "sentences=nltk.sent_tokenize(text)\n",
    "sentences=[nltk.word_tokenize(i) for i in sentences]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['probably',\n",
       "  'effective',\n",
       "  'way',\n",
       "  'achieve',\n",
       "  'paragraph',\n",
       "  'unity',\n",
       "  'express',\n",
       "  'central',\n",
       "  'idea',\n",
       "  'paragraph',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'topic',\n",
       "  'sentences',\n",
       "  'similar',\n",
       "  'mini',\n",
       "  'thesis',\n",
       "  'statements',\n",
       "  'like',\n",
       "  'thesis',\n",
       "  'statement',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'specific',\n",
       "  'main',\n",
       "  'point',\n",
       "  'whereas',\n",
       "  'thesis',\n",
       "  'main',\n",
       "  'point',\n",
       "  'essay',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'main',\n",
       "  'point',\n",
       "  'paragraph',\n",
       "  'like',\n",
       "  'thesis',\n",
       "  'statement',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'unifying',\n",
       "  'function',\n",
       "  'thesis',\n",
       "  'statement',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'alone',\n",
       "  'guarantee',\n",
       "  'unity',\n",
       "  'essay',\n",
       "  'unified',\n",
       "  'paragraphs',\n",
       "  'relate',\n",
       "  'thesis',\n",
       "  'whereas',\n",
       "  'paragraph',\n",
       "  'unified',\n",
       "  'sentences',\n",
       "  'relate',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'note',\n",
       "  'paragraphs',\n",
       "  'need',\n",
       "  'topic',\n",
       "  'sentences',\n",
       "  'particular',\n",
       "  'opening',\n",
       "  'closing',\n",
       "  'paragraphs',\n",
       "  'serve',\n",
       "  'different',\n",
       "  'functions',\n",
       "  'body',\n",
       "  'paragraphs',\n",
       "  'generally',\n",
       "  'topic',\n",
       "  'sentences',\n",
       "  'academic',\n",
       "  'writing',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'nearly',\n",
       "  'always',\n",
       "  'works',\n",
       "  'best',\n",
       "  'beginning',\n",
       "  'paragraph',\n",
       "  'reader',\n",
       "  'knows',\n",
       "  'expect',\n",
       "  'embrace',\n",
       "  'twitter',\n",
       "  'politicians',\n",
       "  'journalists',\n",
       "  'one',\n",
       "  'notable',\n",
       "  'features',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'groups',\n",
       "  'use',\n",
       "  'twitter',\n",
       "  'becoming',\n",
       "  'close',\n",
       "  'requirement',\n",
       "  'paul',\n",
       "  'bernal',\n",
       "  'defence',\n",
       "  'responsible',\n",
       "  'tweeting',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'forecasts',\n",
       "  'central',\n",
       "  'idea',\n",
       "  'main',\n",
       "  'point',\n",
       "  'paragraph',\n",
       "  'politicians',\n",
       "  'journalists',\n",
       "  'rely',\n",
       "  'twitter',\n",
       "  'rest',\n",
       "  'paragraph',\n",
       "  'focus',\n",
       "  'two',\n",
       "  'twitter',\n",
       "  'user',\n",
       "  'groups',\n",
       "  'thereby',\n",
       "  'fulfilling',\n",
       "  'promise',\n",
       "  'made',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'avoiding',\n",
       "  'irrelevant',\n",
       "  'information',\n",
       "  'relate',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'compose',\n",
       "  'unified',\n",
       "  'paragraph']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets stopped the stopwords:\n",
    "for i in range(0,len(sentences)):\n",
    "    sentences[i]=[word for word in sentences[i] if word not in set(stopwords.words('english'))]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, min_count=1)  # if word appear less than  1, it will skip, will get only valuable words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probably': <gensim.models.keyedvectors.Vocab at 0x272bf1d47c8>,\n",
       " 'effective': <gensim.models.keyedvectors.Vocab at 0x272bf254bc8>,\n",
       " 'way': <gensim.models.keyedvectors.Vocab at 0x272bf254288>,\n",
       " 'achieve': <gensim.models.keyedvectors.Vocab at 0x272bf254908>,\n",
       " 'paragraph': <gensim.models.keyedvectors.Vocab at 0x272bf254f08>,\n",
       " 'unity': <gensim.models.keyedvectors.Vocab at 0x272bf254348>,\n",
       " 'express': <gensim.models.keyedvectors.Vocab at 0x272bf254d08>,\n",
       " 'central': <gensim.models.keyedvectors.Vocab at 0x272bf254c08>,\n",
       " 'idea': <gensim.models.keyedvectors.Vocab at 0x272bf254d88>,\n",
       " 'topic': <gensim.models.keyedvectors.Vocab at 0x272bf254988>,\n",
       " 'sentence': <gensim.models.keyedvectors.Vocab at 0x272bf254ac8>,\n",
       " 'sentences': <gensim.models.keyedvectors.Vocab at 0x272bf24c908>,\n",
       " 'similar': <gensim.models.keyedvectors.Vocab at 0x272bf24ca08>,\n",
       " 'mini': <gensim.models.keyedvectors.Vocab at 0x272bf24cb88>,\n",
       " 'thesis': <gensim.models.keyedvectors.Vocab at 0x272bf24c608>,\n",
       " 'statements': <gensim.models.keyedvectors.Vocab at 0x272bf24c9c8>,\n",
       " 'like': <gensim.models.keyedvectors.Vocab at 0x272bf24cc48>,\n",
       " 'statement': <gensim.models.keyedvectors.Vocab at 0x272bf24c688>,\n",
       " 'specific': <gensim.models.keyedvectors.Vocab at 0x272bf24c748>,\n",
       " 'main': <gensim.models.keyedvectors.Vocab at 0x272bf24c0c8>,\n",
       " 'point': <gensim.models.keyedvectors.Vocab at 0x272bf24ce48>,\n",
       " 'whereas': <gensim.models.keyedvectors.Vocab at 0x272bf24c448>,\n",
       " 'essay': <gensim.models.keyedvectors.Vocab at 0x272bf24ca88>,\n",
       " 'unifying': <gensim.models.keyedvectors.Vocab at 0x272bf24c288>,\n",
       " 'function': <gensim.models.keyedvectors.Vocab at 0x272bf24c208>,\n",
       " 'alone': <gensim.models.keyedvectors.Vocab at 0x272bf24cb08>,\n",
       " 'guarantee': <gensim.models.keyedvectors.Vocab at 0x272bf24c788>,\n",
       " 'unified': <gensim.models.keyedvectors.Vocab at 0x272bf24cec8>,\n",
       " 'paragraphs': <gensim.models.keyedvectors.Vocab at 0x272bf24c808>,\n",
       " 'relate': <gensim.models.keyedvectors.Vocab at 0x272bf24c248>,\n",
       " 'note': <gensim.models.keyedvectors.Vocab at 0x272bf24c308>,\n",
       " 'need': <gensim.models.keyedvectors.Vocab at 0x272bf24c388>,\n",
       " 'particular': <gensim.models.keyedvectors.Vocab at 0x272bf24cbc8>,\n",
       " 'opening': <gensim.models.keyedvectors.Vocab at 0x272bf24cc08>,\n",
       " 'closing': <gensim.models.keyedvectors.Vocab at 0x272bf553f88>,\n",
       " 'serve': <gensim.models.keyedvectors.Vocab at 0x272bf553188>,\n",
       " 'different': <gensim.models.keyedvectors.Vocab at 0x272bf5534c8>,\n",
       " 'functions': <gensim.models.keyedvectors.Vocab at 0x272bf553ac8>,\n",
       " 'body': <gensim.models.keyedvectors.Vocab at 0x272bf553488>,\n",
       " 'generally': <gensim.models.keyedvectors.Vocab at 0x272bf553788>,\n",
       " 'academic': <gensim.models.keyedvectors.Vocab at 0x272bf553208>,\n",
       " 'writing': <gensim.models.keyedvectors.Vocab at 0x272bf553508>,\n",
       " 'nearly': <gensim.models.keyedvectors.Vocab at 0x272bf553f48>,\n",
       " 'always': <gensim.models.keyedvectors.Vocab at 0x272bf5537c8>,\n",
       " 'works': <gensim.models.keyedvectors.Vocab at 0x272bf553888>,\n",
       " 'best': <gensim.models.keyedvectors.Vocab at 0x272bf553388>,\n",
       " 'beginning': <gensim.models.keyedvectors.Vocab at 0x272bf5533c8>,\n",
       " 'reader': <gensim.models.keyedvectors.Vocab at 0x272bf553708>,\n",
       " 'knows': <gensim.models.keyedvectors.Vocab at 0x272bf553108>,\n",
       " 'expect': <gensim.models.keyedvectors.Vocab at 0x272bf553408>,\n",
       " 'embrace': <gensim.models.keyedvectors.Vocab at 0x272bf553e08>,\n",
       " 'twitter': <gensim.models.keyedvectors.Vocab at 0x272bf553a88>,\n",
       " 'politicians': <gensim.models.keyedvectors.Vocab at 0x272bf553b48>,\n",
       " 'journalists': <gensim.models.keyedvectors.Vocab at 0x272bf553d88>,\n",
       " 'one': <gensim.models.keyedvectors.Vocab at 0x272bf5532c8>,\n",
       " 'notable': <gensim.models.keyedvectors.Vocab at 0x272bf553ec8>,\n",
       " 'features': <gensim.models.keyedvectors.Vocab at 0x272bf5538c8>,\n",
       " 'recent': <gensim.models.keyedvectors.Vocab at 0x272bf553948>,\n",
       " 'years': <gensim.models.keyedvectors.Vocab at 0x272bf553e88>,\n",
       " 'groups': <gensim.models.keyedvectors.Vocab at 0x272bf553748>,\n",
       " 'use': <gensim.models.keyedvectors.Vocab at 0x272bf553c48>,\n",
       " 'becoming': <gensim.models.keyedvectors.Vocab at 0x272bf553808>,\n",
       " 'close': <gensim.models.keyedvectors.Vocab at 0x272bf5535c8>,\n",
       " 'requirement': <gensim.models.keyedvectors.Vocab at 0x272bf553c08>,\n",
       " 'paul': <gensim.models.keyedvectors.Vocab at 0x272bf553a08>,\n",
       " 'bernal': <gensim.models.keyedvectors.Vocab at 0x272bf553f08>,\n",
       " 'defence': <gensim.models.keyedvectors.Vocab at 0x272bf553148>,\n",
       " 'responsible': <gensim.models.keyedvectors.Vocab at 0x272bf553848>,\n",
       " 'tweeting': <gensim.models.keyedvectors.Vocab at 0x272bf553bc8>,\n",
       " 'forecasts': <gensim.models.keyedvectors.Vocab at 0x272bf553c88>,\n",
       " 'rely': <gensim.models.keyedvectors.Vocab at 0x272bf5536c8>,\n",
       " 'rest': <gensim.models.keyedvectors.Vocab at 0x272bf553588>,\n",
       " 'focus': <gensim.models.keyedvectors.Vocab at 0x272bf553fc8>,\n",
       " 'two': <gensim.models.keyedvectors.Vocab at 0x272bf5539c8>,\n",
       " 'user': <gensim.models.keyedvectors.Vocab at 0x272bf553448>,\n",
       " 'thereby': <gensim.models.keyedvectors.Vocab at 0x272bf2d9288>,\n",
       " 'fulfilling': <gensim.models.keyedvectors.Vocab at 0x272bf2d9408>,\n",
       " 'promise': <gensim.models.keyedvectors.Vocab at 0x272bf2d91c8>,\n",
       " 'made': <gensim.models.keyedvectors.Vocab at 0x272bf2d9888>,\n",
       " 'avoiding': <gensim.models.keyedvectors.Vocab at 0x272bf2d9948>,\n",
       " 'irrelevant': <gensim.models.keyedvectors.Vocab at 0x272bf2d9108>,\n",
       " 'information': <gensim.models.keyedvectors.Vocab at 0x272bf2d9688>,\n",
       " 'compose': <gensim.models.keyedvectors.Vocab at 0x272bf5345c8>}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=model.wv.vocab\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.2671699e-04,  1.6785746e-04,  3.0443314e-03,  4.5509236e-03,\n",
       "       -5.3872936e-04,  1.6720730e-03,  2.0828734e-04,  1.2814670e-03,\n",
       "        4.3203286e-03,  1.4692486e-03, -2.5705684e-03, -3.8945696e-03,\n",
       "       -2.0221067e-03,  1.6534737e-03,  4.5239431e-04, -4.7686958e-04,\n",
       "       -4.2808377e-03, -3.6210059e-03, -1.2330529e-03,  1.9387755e-03,\n",
       "       -3.0960115e-03,  7.6036371e-04, -4.8247357e-03,  1.9486472e-03,\n",
       "       -3.1785364e-03, -4.9568230e-04, -1.1967772e-03, -2.0714903e-03,\n",
       "       -1.9724548e-03, -9.9403132e-04,  2.8624453e-03, -1.1177268e-03,\n",
       "       -1.7071258e-03, -1.6949495e-03,  3.2527836e-03,  2.1800648e-03,\n",
       "       -3.6508376e-03,  4.9968353e-03, -4.2304057e-03, -3.4308855e-03,\n",
       "       -2.0145492e-04,  2.9220851e-03, -2.3648178e-03,  4.5922664e-03,\n",
       "        3.2257652e-03,  1.7874800e-03, -2.2921546e-03,  1.7844295e-03,\n",
       "       -1.6672607e-03, -4.5956727e-03,  4.5379335e-03,  2.0191055e-03,\n",
       "        3.0854498e-03,  2.2059630e-03,  1.8084837e-03,  3.3854358e-03,\n",
       "       -4.9634604e-03,  2.2640824e-03,  4.6925205e-03, -2.1519398e-03,\n",
       "       -4.8481971e-03, -2.3704225e-03, -5.0186580e-03, -4.3296544e-03,\n",
       "        2.3856051e-03, -4.6454496e-03, -3.6957797e-03, -9.9069800e-04,\n",
       "       -3.6080775e-03, -3.1295305e-05,  1.5741795e-03, -3.1568427e-04,\n",
       "       -9.2429553e-05,  1.1279889e-03, -3.0697798e-03, -7.5502653e-04,\n",
       "        1.9098617e-03,  4.5635146e-03, -8.9014962e-04,  2.9205371e-04,\n",
       "        4.4961902e-03, -4.7714734e-03,  3.6039848e-03, -3.0788989e-04,\n",
       "        8.2071207e-04, -2.6779335e-03,  4.2273561e-03,  3.8331316e-03,\n",
       "        4.3929373e-03, -3.1086791e-03,  3.4451273e-03, -2.9269231e-03,\n",
       "       -6.4426364e-04, -3.9716763e-03, -1.2924155e-03,  2.3427561e-03,\n",
       "       -1.8716472e-03, -2.0100311e-03,  6.3600519e-04,  3.7876319e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets find the word vector of a particular word:\n",
    "vector=model.wv['central']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('forecasts', 0.27768009901046753),\n",
       " ('function', 0.24482116103172302),\n",
       " ('different', 0.2321092039346695),\n",
       " ('irrelevant', 0.18512892723083496),\n",
       " ('knows', 0.184354767203331),\n",
       " ('twitter', 0.1798315942287445),\n",
       " ('becoming', 0.16909268498420715),\n",
       " ('paul', 0.168805330991745),\n",
       " ('whereas', 0.16762787103652954),\n",
       " ('sentence', 0.15543414652347565)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets find a similar word of a word:\n",
    "similar_word=model.wv.most_similar('central')\n",
    "similar_word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
